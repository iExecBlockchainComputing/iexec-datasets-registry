{
  "description": "Detect Inappropriate Content In Your Images. Use Yahoo Open NSFW to detect the possibility that your image is not suitable for work (pornographic content). Detection ranges from 0 to 100%.",
  "license": "BSD 2-Clause Simplified License",
  "author": "iExec",
  "social": {
    "website": "https://modeldepot.io/mikeshi/yahoo-open-nsfw",
    "github": "https://github.com/yahoo/open_nsfw"
  },
  "logo": "logo.png",
  "dataset": {
    "owner": "0xA1162f07afC3e45Ae89D2252706eB355F6349641",
    "name": "YahooOpenNSFW",
    "multiaddr": "https://raw.githubusercontent.com/iExecBlockchainComputing/iexec-datasets/master/nsfw_model/nsfw_model.zip.enc",
    "checksum": "0x0000000000000000000000000000000000000000000000000000000000000000"
  },
  "dapps": [
    {
      "name": "nsfwPrediction",
      "addresses": {
        "1": "0x007D38be25E8A8101d876C1396dF72258dB5b092",
        "42": "0xb5B6D5C9b3CC329148510de40BdAB38e6610e1a7"
      },
      "buyConf": {
        "params": { "0": "https://www.w3schools.com/w3css/img_lights.jpg" }
      }
    }
  ]
}
